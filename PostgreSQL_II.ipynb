{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PostgreSQL_II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIHiDC5cQM8RJbKR24Ec79",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabeMaldonado/SQL/blob/master/PostgreSQL_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii_nQWZ4hpn7",
        "colab_type": "text"
      },
      "source": [
        "Notes on Postgresql for Data Analysis -- II\n",
        "\n",
        "- [1. Aggregation](#1)\n",
        "- [2. Date Functions](#2)\n",
        "\n",
        "<a name='1'></a>\n",
        "# Aggregation\n",
        "\n",
        "SQL allows us to transform and aggregate our data hence making queries more efficient and results more meaningful. Aggregations work down column and not across rows. Below are some of the aggregation functions that we can use in SQL:\n",
        "*   `COUNT` -- counts how many rows are in a particular column\n",
        "*   `SUM` -- adds up all the values in a particular column\n",
        "*   `MIN`  -- returns the minimun value in a particular column\n",
        "*   `MAX`  -- returns the maximun value in a particular column\n",
        "*   `AVERAGE` -- calculates the average in a particular column\n",
        "\n",
        "### Examples:\n",
        "\n",
        "1. To count the number of rows in the *accounts* table:\n",
        "```\n",
        "SELECT COUNT(*)\n",
        "FROM accounts;\n",
        "```\n",
        "\n",
        "2. Return the total amount of `poster_qty` paper ordered:\n",
        "```\n",
        "SELECT SUM(poster_qty)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "3. Return the total amount of `standard_qty` paper orderd:\n",
        "```\n",
        "SELECT SUM(standard_qty)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "4. Return the `total_amt_usd` of sales:\n",
        "```\n",
        "SELECT SUM(total_amt_usd)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "5. Return the ratio between the totals of `standard_amt_usd` & `standard_qty`\n",
        "```\n",
        "SELECT SUM(standard_amt_usd) / SUM(standard_qty)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "6. Return the earliest order ever placed:\n",
        "```\n",
        "SELCT MIN(occurred_at)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "7. Return the latests order placed\n",
        "```\n",
        "SELECT MAX(occurred_at)\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "8. Return the average for each paper typer as well as its amount spent per order\n",
        "```\n",
        "SELECT AVG(standard_qty) AS avg_standard,\n",
        "       AVG(standard_amt_usd) AS avg_standard_amt,\n",
        "       AVG(gloss_qty) AS avg_gloss,\n",
        "       AVG(gloss_amt_usd) AS avg_gloss_amt,\n",
        "       AVG(poster_qty) AS avg_poster,\n",
        "       AVG(poster_amt_usd) AS avg_poster_amt\n",
        "FROM orders;\n",
        "```\n",
        "## GROUP BY\n",
        "Using a `GROUP BY` clause allows us to create segments that will aggregate independent from each other. For instance, and using the queries above, we could sum up all of the sales of each paper type for each account. The `GROUP BY` clause always goes between the `WHERE` and `ORDER BY` clause. \n",
        "\n",
        "### Examples\n",
        "\n",
        "1. Return which account placed the earliest orders:\n",
        "```\n",
        "SELECT accounts.name AS account_name,\n",
        "       MIN(orders.occurred_at) AS date_ordered\n",
        "FROM accounts\n",
        "JOIN orders\n",
        "ON accounts.id = orders.account_id\n",
        "GROUP BY accounts.name;\n",
        "```\n",
        "\n",
        "2. Return the total sales for each account:\n",
        "```\n",
        "SELECT accounts.name AS account_name,\n",
        "       SUM(orders.total_amt_usd) AS total\n",
        "FROM accounts\n",
        "JOIN orders\n",
        "ON accounts.id = orders.account_id\n",
        "GROUP BY accounts.name;\n",
        "```\n",
        "\n",
        "3. Return the smallest order in $ value for each account:\n",
        "```\n",
        "SELECT accounts.name, MIN(orders.total_amt_usd) AS smallest_order\n",
        "FROM accounts\n",
        "JOIN orders\n",
        "ON accounts.id = orders.account_id\n",
        "GROUP BY accounts.name\n",
        "ORDER BY smallest_order;\n",
        "```\n",
        "\n",
        "4. Return the number of sales rep for each region:\n",
        "```\n",
        "SELECT region.name, COUNT(*) AS num_reps\n",
        "FROM region\n",
        "JOIN sales_reps\n",
        "ON region.id = sales_reps.region_id\n",
        "GROUP BY region.name\n",
        "ORDER BY num_reps\n",
        "```\n",
        "4. Return the average amount of each type of paper purchased for each account. \n",
        "```\n",
        "SELECT accounts.name, \n",
        "       AVG(standard_qty) AS avg_standard,\n",
        "       AVG(gloss_qty) AS avg_gloss,\n",
        "       AVG(poster_qty) AS avg_poster\n",
        "FROM accounts\n",
        "JOIN orders\n",
        "ON accounts.id = orders.account_id\n",
        "GROUP BY accounts.name;\n",
        "```\n",
        "\n",
        "5. Return the average amount spent on each type of paper for each account. Sort A-Z.\n",
        "```\n",
        "SELECT accounts.name, \n",
        "       AVG(standard_amt_usd) AS avg_standard_usd,\n",
        "       AVG(gloss_amt_usd) AS avg_gloss_usd,\n",
        "       AVG(poster_amt_usd) AS avg_poster_usd\n",
        "FROM accounts\n",
        "JOIN orders\n",
        "ON accounts.id = orders.account_id\n",
        "GROUP BY accounts.name\n",
        "ORDER BY accounts.name;\n",
        "```\n",
        "\n",
        "6. Return the number of times a particular channel was used in a web event for each region.\n",
        "```\n",
        "SELECT region.name, \n",
        "       web_events.channel, \n",
        "       COUNT(*) num_events\n",
        "FROM accounts\n",
        "JOIN web_events\n",
        "ON accounts.id = web_events.account_id\n",
        "JOIN sales_reps \n",
        "ON sales_reps.id = accounts.sales_rep_id\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ByL-lQIfogN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## DISTINCT\n",
        "\n",
        "The `DISTINCT` clause is always used with the `SELECT` clause to return the unique rows for all columns written in the `SELECT` statement. Its syntax is as follows:\n",
        "```\n",
        "SELECT DISTINCT column1, column2, column3\n",
        "FROM table1;\n",
        "```\n",
        "\n",
        "### Example:\n",
        "\n",
        "1. Use DISTINCT to check if there are any accounts associated with more than one region. \n",
        "```\n",
        "SELECT DISTINCT id, name\n",
        "FROM accounts;\n",
        "```\n",
        "\n",
        "## HAVING\n",
        "The `HAVING` clause is used to filtered data based on a particular criteria. `HAVING` is similar to `WHERE` in concept with the difference that `HAVING` is used when the data has been aggregated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCbGOpNA2_Pq",
        "colab_type": "text"
      },
      "source": [
        "<a name='2'></a>\n",
        "\n",
        "## DATE FUNCTIONS\n",
        "\n",
        "Working with data is somewhat cumbersome as each timestamp is treated as unique and it is not possible to aggregate. Databases use a different date format. They represent dates from the least to the most granular part of the date: `YYYY:MM:DD`. This format is very useful and practical as the dates are sorted alphabetically and also in chronological order so when we want o retrieve the newests or oldest date-- it is correct and a lot easier to sort by `YYYY` rather than any other format. Another benefit is the date can be easily **truncated** so they can be group for analysis. \n",
        "Let's say we need to retrieve data for a particular day:\n",
        "`2020-07-10- 11:50:01` since each data point has a unique timnestamp we would not be able to group it and it will only return one data point. To group by day, we would need to adjust all the times for July 10th to read `2020-07-10 00:00:00`. By doing this we would retrieve every event that occured for all hours. minutes and secods of July 10th. They will al bee group together into a single grouping. To achieve this we use `DATE_TRUNC`.\n",
        "\n",
        "`DATE_TRUNC` allows us to truncate our date to a particular part of our datetime column. We can truncate by `day, month, year`. In the example below, we're showing how to get the total number of orders placed daily. We use `DATE_TRUNC` in the `SELECT` clause. The first argument is the truncation method, which is daily in this case, and the second argument is the column that contains the order's dates. In the second line, we sum all the orders to get the total of daily orders. It is important to group by and order the query by the same statement used in the `SELECT` clause to ensure consistent results. \n",
        "```\n",
        "SELECT DATE_TRUNC('day',  order_date) AS day\n",
        "       SUM(orders) AS orders_sum\n",
        "FROM orders\n",
        "GROUP BY DATE_TRUNC('day',  order_date)\n",
        "ORDER BY DATE_TRUNC('day',  order_date)\n",
        "```\n",
        "We can use `DATE_TRUNC` to aggregate dates at a very granular level-- down to the second. Here are the most common options used when truncating and their corresponding outputs:\n",
        "\n",
        "<pre>\n",
        "INPUT                                               OUTPUT\n",
        "DATE_TRUNC('second', 2020-07-10 12:20:01)         2020-07-10 12:20:01 \n",
        "DATE_TRUNC('day', 2020-07-10 12:20:01)            2020-07-10 00:00:00\n",
        "DATE_TRUNC('month', 2020-07-10 12:20:01)          2020-07-10 00:00:00\n",
        "DATE_TRUNC('year', 2020-07-10 12:20:01)           2020-01-10 00:00:00\n",
        "</pre>\n",
        "\n",
        "There are instances where we might want to retrieve a given part of a date. For instance, we want to know what day of the week sees the more sales. To get the day of the week, we would use `DATE_PART`. This function allows us to pull the part of the date that we are interested in. Let's look at the following example:\n",
        "\n",
        "```\n",
        "SELECT DATE_PART('dow', order_date) AS day_of_week\n",
        "       SUM(total) AS total_qty\n",
        "FROM orders\n",
        "GROUP BY 1\n",
        "ORDER BY 2 DESC\n",
        "```\n",
        "We use `DATE_PART` in the `SELECT` stament. Its first argument is `dow` which stands for *day of the week* since that is the metric we want to evaluate upon. DOW will return a numeric value form `0 - 6` representing Sunday to Saturday   Then we sum the all the orders. The one and two in the query represent the columns in the `SELECT` statement.\n",
        "\n",
        "### Examples of working with dates:\n",
        "\n",
        "1.   Return the dollar ammount for all sales in a yearly basis. Sort in HI-LO way for the dollar amount.\n",
        "```\n",
        "SELECT DATE_TRUNC('year', occurred_at) AS year,\n",
        "       SUM(total_amt_usd) as total_amt_usd_year\n",
        "FROM orders\n",
        "GROUP BY DATE_TRUNC('year', occurred_at)\n",
        "ORDER BY SUM(total_amt_usd) DESC;\n",
        "```\n",
        "\n",
        "2.  Return the best performing months in terms of dollar amounts:\n",
        "```\n",
        "SELECT DATE_PART('month', occurred_at) AS month,\n",
        "       SUM(total_amt_usd) as total_amt_usd_year\n",
        "FROM orders\n",
        "GROUP BY DATE_PART('month', occurred_at)\n",
        "ORDER BY SUM(total_amt_usd) DESC;\n",
        "```\n",
        "\n",
        "3.  Return the best performing years in terms of total orders placed:\n",
        "```\n",
        "SELECT DATE_PART('year', occurred_at) AS ord_year,  \n",
        "       COUNT(*) AS total_sales\n",
        "FROM orders\n",
        "GROUP BY 1\n",
        "ORDER BY 2 DESC;\n",
        "```\n",
        "\n",
        "4.  Return the best performing months in terms of total orders placed:\n",
        "```\n",
        "SELECT DATE_PART('month', occurred_at) AS month,\n",
        "       COUNT(*) as total\n",
        "FROM orders\n",
        "GROUP BY DATE_PART('month', occurred_at)\n",
        "ORDER BY SUM(total) DESC;\n",
        "```\n",
        "\n",
        "5.   Return the month and year in which Walmart spend the most amount of dollars in gloss paper:\n",
        "```\n",
        "SELECT DATE_TRUNC('month', occurred_at) AS order_date, accounts.name,\n",
        "       SUM(orders.gloss_amt_usd) AS gloss_tot_amt\n",
        "FROM orders\n",
        "JOIN accounts\n",
        "ON orders.account_id = accounts.id\n",
        "WHERE accounts.name = 'Walmart'\n",
        "GROUP BY 1, 2\n",
        "ORDER BY 3 DESC\n",
        "LIMIT 1;\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QDpc6r9I560",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}